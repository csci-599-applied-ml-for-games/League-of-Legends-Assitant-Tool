{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2.1.0\nsys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\nnumpy 1.18.1\npandas 0.23.3\nsklearn 0.21.3\ntensorflow 2.1.0\ntensorflow_core.python.keras.api._v2.keras 2.2.4-tf\nTraining Images ->  51596\nValidation Images ->  14882\nTest Images ->  188\n"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n",
    "\n",
    "\n",
    "training_path = pathlib.Path('./lol_data_2/training')\n",
    "validation_path = pathlib.Path('./lol_data_2/valid')\n",
    "test_path = pathlib.Path('./lol_data_2/test')\n",
    "\n",
    "train_image_paths = list(training_path.glob('*/*'))  \n",
    "valid_image_paths = list(validation_path.glob('*/*'))  \n",
    "test_image_paths = list(test_path.glob('*/'))  \n",
    "\n",
    "train_image_paths = [str(path) for path in train_image_paths]\n",
    "valid_image_paths = [str(path) for path in valid_image_paths]\n",
    "test_image_paths = [str(path) for path in test_image_paths]\n",
    "\n",
    "random.shuffle(train_image_paths)\n",
    "random.shuffle(valid_image_paths)\n",
    "random.shuffle(test_image_paths)\n",
    "\n",
    "train_image_count = len(train_image_paths)\n",
    "valid_image_count = len(valid_image_paths)\n",
    "test_image_count = len(test_image_paths)\n",
    "\n",
    "print(\"Training Images -> \", train_image_count)\n",
    "print(\"Validation Images -> \", valid_image_count)\n",
    "print(\"Test Images -> \", test_image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/job:localhost/replica:0/task:0/device:GPU:0 /job:localhost/replica:0/task:0/device:GPU:0\n"
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "\n",
    "    gpu_a = tf.random.normal([10000, 1000])\n",
    "\n",
    "    gpu_b = tf.random.normal([1000, 2000])\n",
    "\n",
    "    print(gpu_a.device, gpu_b.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['lol_data_2\\\\training\\\\Thornmail_item\\\\Thornmail_250.png',\n 'lol_data_2\\\\training\\\\Blade_of_the_Ruined_King_item\\\\Blade_of_the_Ruined_King_871.png',\n 'lol_data_2\\\\training\\\\Bloodthirster_item\\\\Bloodthirster_74.png',\n 'lol_data_2\\\\training\\\\Lost_Chapter_item\\\\Lost_Chapter_184.png',\n 'lol_data_2\\\\training\\\\Ionian_Boots_of_Lucidity_item\\\\Ionian_Boots_of_Lucidity_242.png']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['lol_data_2\\\\valid\\\\Thornmail_item\\\\Thornmail_356.png',\n 'lol_data_2\\\\valid\\\\Black_Cleaver_item\\\\Black_Cleaver_3511.png',\n 'lol_data_2\\\\valid\\\\Trinity_Force_item\\\\Trinity_Force_3571.png',\n 'lol_data_2\\\\valid\\\\Steel_Shoulderguards_item\\\\Steel_Shoulderguards_294.png',\n 'lol_data_2\\\\valid\\\\Farsight_Alteration_item\\\\Farsight_Alteration_313.png']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['lol_data_2\\\\test\\\\Steel_Shoulderguards_item.png',\n \"lol_data_2\\\\test\\\\Doran's_Shield_item.png\",\n 'lol_data_2\\\\test\\\\Trinity_Force_item1.png',\n \"lol_data_2\\\\test\\\\Youmuu's_Ghostblade_item1.png\",\n 'lol_data_2\\\\test\\\\Black_Cleaver_item.png']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['Abyssal_Mask_item',\n 'Adaptive_Helm_item',\n 'Aegis_of_the_Legion_item',\n 'Aether_Wisp_item',\n 'Amplifying_Tome_item',\n \"Archangel's_Staff_item\",\n 'Ardent_Censer_item',\n \"Athene's_Unholy_Grail_item\",\n 'B.F.Sword_item',\n \"Bami's_Cinder_item\",\n \"Banshee's_Veil_item\",\n \"Berserker's_Greaves_item\",\n 'Bilgewater_Cutlass_item',\n 'Black_Cleaver_item',\n 'Blade_of_the_Ruined_King_item',\n 'Blasting_Wand_item',\n 'Bloodrazor_item',\n 'Bloodthirster_item',\n 'Boots_of_Mobility_item',\n 'Boots_of_Speed_item',\n 'Boots_of_Swiftness_item',\n 'Bramble_Vest_item',\n 'Bulwark_of_the_Mountain_item',\n 'Catalyst_of_Aeons_item',\n \"Caulfield's_Warhammer_item\",\n 'Chain_Vest_item',\n 'Chalice_of_Harmony_item',\n 'Cinderhulk_item',\n 'Cloak_of_Agility_item',\n 'Cloth_Armor_item',\n 'Control_Ward_item',\n 'Corrupting_Potion_item',\n 'Crystalline_Bracer_item',\n 'Cull_item',\n 'Dagger_item',\n 'Dark_Seal_item',\n \"Dead_Man's_Plate_item\",\n \"Death's_Dance_item\",\n \"Doran's_Blade_item\",\n \"Doran's_Ring_item\",\n \"Doran's_Shield_item\",\n 'Duskblade_of_Draktharr_item',\n 'Edge_of_Night_item',\n 'Elixir_of_Iron_item',\n 'Elixir_of_Sorcery_item',\n 'Elixir_of_Wrath_item',\n 'Essence_Reaver_item',\n \"Executioner's_Calling_item\",\n 'Eye_of_the_Herald_buff',\n 'Faerie_Charm_item',\n 'Farsight_Alteration_item',\n 'Fiendish_Codex_item',\n 'Forbidden_Idol_item',\n 'Frostfang_item',\n 'Frozen_Heart_item',\n 'Frozen_Mallet_item',\n 'Gargoyle_Stoneplate_item',\n \"Giant's_Belt_item\",\n 'Glacial_Shroud_item',\n 'Guardian_Angel_item',\n \"Guinsoo's_Rageblade_item\",\n 'Harrowing_Crescent_item',\n 'Haunting_Guise_item',\n 'Health_Potion_item',\n 'Hexdrinker_item',\n 'Hextech_GLP-800_item',\n 'Hextech_Gunblade_item',\n 'Hextech_Protobelt-0_item',\n 'Hextech_Revolver_item',\n \"Hunter's_Machete_item\",\n \"Hunter's_Talisman_item\",\n 'Iceborn_Gauntlet_item',\n 'Infinity_Edge_item',\n 'Ionian_Boots_of_Lucidity_item',\n \"Jaurim's_Fist_item\",\n 'Kindlegem_item',\n 'Kircheis_Shard_item',\n \"Knight's_Vow_item\",\n 'Last_Whisper_item',\n \"Liandry's_Torment_item\",\n 'Lich_Bane_item',\n 'Locket_of_the_Iron_Solari_item',\n 'Long_Sword_item',\n \"Lord_Dominik's_Regards_item\",\n 'Lost_Chapter_item',\n \"Luden's_Echo_item\",\n 'Manamune_item',\n 'Maw_of_Malmortius_item',\n \"Mejai's_Soulstealer_item\",\n 'Mercurial_Scimitar_item',\n \"Mercury's_Treads_item\",\n \"Mikael's_Crucible_item\",\n 'Morellonomicon_item',\n 'Mortal_Reminder_item',\n \"Nashor's_Tooth_item\",\n 'Needlessly_Large_Rod_item',\n 'Negatron_Cloak_item',\n 'Ninja_Tabi_item',\n 'Null-Magic_Mantle_item',\n 'Oracle_Lens_item',\n 'Pauldrons_of_Whiterock_item',\n 'Phage_item',\n 'Phantom_Dancer_item',\n 'Pickaxe_item',\n 'Prototype_Hex_Core_item',\n 'Quicksilver_Sash_item',\n \"Rabadon's_Deathcap_item\",\n \"Randuin's_Omen_item\",\n 'Rapid_Firecannon_item',\n 'Ravenous_Hydra_item',\n 'Recurve_Bow_item',\n 'Redemption_item',\n 'Refillable_Potion_item',\n 'Rejuvenation_Bead_item',\n 'Relic_Shield_item',\n 'Righteous_Glory_item',\n 'Rod_of_Ages_item',\n 'Ruby_Crystal_item',\n \"Runaan's_Hurricane_item\",\n 'Runesteel_Spaulders_item',\n 'Runic_Echoes_item',\n \"Rylai's_Crystal_Scepter_item\",\n 'Sanguine_Blade_item',\n 'Sapphire_Crystal_item',\n \"Seeker's_Armguard_item\",\n \"Seraph's_Embrace_item\",\n 'Serrated_Dirk_item',\n 'Sheen_item',\n \"Shurelya's_Reverie_item\",\n \"Skirmisher's_Sabre_item\",\n 'Slightly_Magical_Boots_item',\n \"Sorcerer's_Shoes_item\",\n 'Spectral_Sickle_item',\n \"Spectre's_Cowl_item\",\n 'Spellbinder_item',\n \"Spellthief's_Edge_item\",\n 'Spirit_Visage_item',\n \"Stalker's_Blade_item\",\n 'Statikk_Shiv_item',\n 'Steel_Shoulderguards_item',\n \"Sterak's_Gage_item\",\n 'Stinger_item',\n 'Stopwatch_item',\n 'Stormrazor_item',\n 'Sunfire_Cape_item',\n \"Targon's_Buckler_item\",\n 'Tear_of_the_Goddess_item',\n 'The_Black_Spear_item',\n 'The_Hex_Core_mk-2_item',\n 'The_Hex_Core_mk-_item',\n 'Thornmail_item',\n 'Tiamat_item',\n 'Titanic_Hydra_item',\n 'Total_Biscuit_of_Everlasting_Will_item',\n 'Trinity_Force_item',\n 'Twin_Shadows_item',\n 'Umbral_Glaive_item',\n 'Vampiric_Scepter_item',\n 'Void_Staff_item',\n \"Warden's_Mail_item\",\n 'Warding_Totem_item',\n \"Warmog's_Armor_item\",\n 'Warrior_item',\n \"Wit's_End_item\",\n \"Youmuu's_Ghostblade_item\",\n 'Zeal_item',\n \"Zeke's_Convergence_item\",\n \"Zhonya's_Hourglass_item\",\n 'none',\n 'oblivion_orb_item']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = sorted(item.name for item in training_path.glob('*/') if item.is_dir())\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "lol_data_2\\training\\Thornmail_item\\Thornmail_250.png  --->   Thornmail_item\nlol_data_2\\training\\Blade_of_the_Ruined_King_item\\Blade_of_the_Ruined_King_871.png  --->   Blade_of_the_Ruined_King_item\nlol_data_2\\training\\Bloodthirster_item\\Bloodthirster_74.png  --->   Bloodthirster_item\nlol_data_2\\training\\Lost_Chapter_item\\Lost_Chapter_184.png  --->   Lost_Chapter_item\nlol_data_2\\training\\Ionian_Boots_of_Lucidity_item\\Ionian_Boots_of_Lucidity_242.png  --->   Ionian_Boots_of_Lucidity_item\n"
    }
   ],
   "source": [
    "training_image_labels = [pathlib.Path(path).parent.name for path in train_image_paths]\n",
    "for image, label in zip(train_image_paths[:5], training_image_labels[:5]):\n",
    "    print(image, ' --->  ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_info = []\n",
    "for image_path, label in zip(train_image_paths, training_image_labels):\n",
    "    train_labels_info.append((image_path, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[('lol_data_2\\\\training\\\\Thornmail_item\\\\Thornmail_250.png', 'Thornmail_item'),\n ('lol_data_2\\\\training\\\\Blade_of_the_Ruined_King_item\\\\Blade_of_the_Ruined_King_871.png',\n  'Blade_of_the_Ruined_King_item'),\n ('lol_data_2\\\\training\\\\Bloodthirster_item\\\\Bloodthirster_74.png',\n  'Bloodthirster_item'),\n ('lol_data_2\\\\training\\\\Lost_Chapter_item\\\\Lost_Chapter_184.png',\n  'Lost_Chapter_item'),\n ('lol_data_2\\\\training\\\\Ionian_Boots_of_Lucidity_item\\\\Ionian_Boots_of_Lucidity_242.png',\n  'Ionian_Boots_of_Lucidity_item')]\n"
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(train_labels_info[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "lol_data_2\\valid\\Thornmail_item\\Thornmail_356.png  --->Thornmail_item\nlol_data_2\\valid\\Black_Cleaver_item\\Black_Cleaver_3511.png  --->   Black_Cleaver_item\nlol_data_2\\valid\\Trinity_Force_item\\Trinity_Force_3571.png  --->   Trinity_Force_item\nlol_data_2\\valid\\Steel_Shoulderguards_item\\Steel_Shoulderguards_294.png  --->   Steel_Shoulderguards_item\nlol_data_2\\valid\\Farsight_Alteration_item\\Farsight_Alteration_313.png  --->   Farsight_Alteration_item\n"
    }
   ],
   "source": [
    "valid_image_labels = [pathlib.Path(path).parent.name for path in valid_image_paths]\n",
    "for image, label in zip(valid_image_paths[:5], valid_image_labels[:5]):\n",
    "    print(image, ' --->  ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels_info = []\n",
    "for image_path, label in zip(valid_image_paths, valid_image_labels):\n",
    "    valid_labels_info.append((image_path, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[('lol_data_2\\\\valid\\\\Thornmail_item\\\\Thornmail_356.png', 'Thornmail_item'),\n ('lol_data_2\\\\valid\\\\Black_Cleaver_item\\\\Black_Cleaver_3511.png',\n  'Black_Cleaver_item'),\n ('lol_data_2\\\\valid\\\\Trinity_Force_item\\\\Trinity_Force_3571.png',\n  'Trinity_Force_item'),\n ('lol_data_2\\\\valid\\\\Steel_Shoulderguards_item\\\\Steel_Shoulderguards_294.png',\n  'Steel_Shoulderguards_item'),\n ('lol_data_2\\\\valid\\\\Farsight_Alteration_item\\\\Farsight_Alteration_313.png',\n  'Farsight_Alteration_item')]\n"
    }
   ],
   "source": [
    "pprint.pprint(valid_labels_info[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "lol_data_2\\test\\Steel_Shoulderguards_item.png  --->   Steel_Shoulderguards_item\nlol_data_2\\test\\Doran's_Shield_item.png  --->   Doran's_Shield_item\nlol_data_2\\test\\Trinity_Force_item1.png  --->   Trinity_Force_item1\nlol_data_2\\test\\Youmuu's_Ghostblade_item1.png  --->   Youmuu's_Ghostblade_item1\nlol_data_2\\test\\Black_Cleaver_item.png  --->   Black_Cleaver_item\n"
    }
   ],
   "source": [
    "test_image_labels = [path.split('\\\\')[2].split('.')[0] for path in test_image_paths]\n",
    "for image, label in zip(test_image_paths[:5], test_image_labels[:5]):\n",
    "    print(image, ' --->  ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_info = []\n",
    "for image_path, label in zip(test_image_paths, test_image_labels):\n",
    "    test_labels_info.append((image_path, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "filepath  \\\n0  lol_data_2\\training\\Thornmail_item\\Thornmail_2...   \n1  lol_data_2\\training\\Blade_of_the_Ruined_King_i...   \n2  lol_data_2\\training\\Bloodthirster_item\\Bloodth...   \n3  lol_data_2\\training\\Lost_Chapter_item\\Lost_Cha...   \n4  lol_data_2\\training\\Ionian_Boots_of_Lucidity_i...   \n\n                           class  \n0                 Thornmail_item  \n1  Blade_of_the_Ruined_King_item  \n2             Bloodthirster_item  \n3              Lost_Chapter_item  \n4  Ionian_Boots_of_Lucidity_item  \n                                            filepath  \\\n0  lol_data_2\\valid\\Thornmail_item\\Thornmail_356.png   \n1  lol_data_2\\valid\\Black_Cleaver_item\\Black_Clea...   \n2  lol_data_2\\valid\\Trinity_Force_item\\Trinity_Fo...   \n3  lol_data_2\\valid\\Steel_Shoulderguards_item\\Ste...   \n4  lol_data_2\\valid\\Farsight_Alteration_item\\Fars...   \n\n                       class  \n0             Thornmail_item  \n1         Black_Cleaver_item  \n2         Trinity_Force_item  \n3  Steel_Shoulderguards_item  \n4   Farsight_Alteration_item  \n                                        filepath                      class\n0  lol_data_2\\test\\Steel_Shoulderguards_item.png  Steel_Shoulderguards_item\n1        lol_data_2\\test\\Doran's_Shield_item.png        Doran's_Shield_item\n2        lol_data_2\\test\\Trinity_Force_item1.png        Trinity_Force_item1\n3  lol_data_2\\test\\Youmuu's_Ghostblade_item1.png  Youmuu's_Ghostblade_item1\n4         lol_data_2\\test\\Black_Cleaver_item.png         Black_Cleaver_item\n"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_labels_info)\n",
    "valid_df = pd.DataFrame(valid_labels_info)\n",
    "test_df = pd.DataFrame(test_labels_info)\n",
    "\n",
    "train_df.columns = valid_df.columns =test_df.columns = ['filepath', 'class']\n",
    "\n",
    "print(train_df.head())\n",
    "print(valid_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 51596 validated image filenames belonging to 170 classes.\nFound 14882 validated image filenames belonging to 170 classes.\nFound 167 validated image filenames belonging to 170 classes.\n"
    }
   ],
   "source": [
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "batch_size = 128\n",
    "num_classes = 170\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    #像素值 都除以255\n",
    "    rescale = 1./255,\n",
    "    # 图片随机旋转 (5度以内)\n",
    "    rotation_range = 20,\n",
    "    # 图片左右位移  20%限度以内\n",
    "    width_shift_range = 0.2,\n",
    "    # 图片上下位移  20%限度以内\n",
    "    height_shift_range = 0.2,\n",
    "    # 图像剪切强度\n",
    "    shear_range = 0.2,\n",
    "    # 图像缩放强度\n",
    "    zoom_range = 0.2,\n",
    "    # 是否水平翻转\n",
    "    horizontal_flip = False,\n",
    "    # 放大缩小吼， 像素填充方式\n",
    "    fill_mode = 'nearest',\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df, directory = './',\n",
    "                                                    x_col = 'filepath',\n",
    "                                                    y_col = 'class',\n",
    "                                                    classes = label_names,\n",
    "                                                    target_size = (height, width),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    seed = 2,\n",
    "                                                    shuffle = True,\n",
    "                                                    class_mode = \"categorical\")\n",
    "\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    ")\n",
    "valid_generator = valid_datagen.flow_from_dataframe(valid_df, directory = './',\n",
    "                                                    x_col = 'filepath',\n",
    "                                                    y_col = 'class',\n",
    "                                                    classes = label_names,\n",
    "                                                    target_size = (height, width),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    seed = 24,\n",
    "                                                    shuffle = True,\n",
    "                                                    class_mode = \"categorical\")\n",
    "\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    ")\n",
    "test_generator = test_datagen.flow_from_dataframe(test_df, directory = './',\n",
    "                                                    x_col = 'filepath',\n",
    "                                                    y_col = 'class',\n",
    "                                                    classes = label_names,\n",
    "                                                    target_size = (height, width),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    seed = 8,\n",
    "                                                    shuffle = True,\n",
    "                                                    class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training Generator Sample ->  51596\nValidation Generator Sample ->  14882\nTest Generator Sample ->  167\n"
    }
   ],
   "source": [
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "test_num = test_generator.samples\n",
    "\n",
    "print(\"Training Generator Sample -> \", train_num)\n",
    "print(\"Validation Generator Sample -> \", valid_num)\n",
    "print(\"Test Generator Sample -> \", test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(128, 64, 64, 3) (128, 170)\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n(128, 64, 64, 3) (128, 170)\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    x, y = train_generator.next()\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 64, 64, 16)        448       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 64, 64, 16)        2320      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 32, 32, 16)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 4096)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               524416    \n_________________________________________________________________\nalpha_dropout (AlphaDropout) (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 170)               21930     \n=================================================================\nTotal params: 618,426\nTrainable params: 618,426\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Conv2D(filters=16, kernel_size = 3, padding='same',\n",
    "                       activation = 'selu', input_shape = [width, height, channels]),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size = 3, \n",
    "                        padding='same', activation = 'selu'),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=32, kernel_size = 3, \n",
    "                        padding='same', activation = 'selu'),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size = 3, \n",
    "                        padding='same', activation = 'selu'),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size = 3, padding='same',\n",
    "                       activation = 'selu', input_shape = [width, height, channels]),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size = 3, \n",
    "                        padding='same', activation = 'selu'),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation = 'selu'),\n",
    "    keras.layers.AlphaDropout(rate=0.5),\n",
    "    \n",
    "    keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer = \"adam\", metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = './lol-callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "output_model_file = os.path.join(logdir, \"item_detection_model.h5\")\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(output_model_file, monitor='val_loss', mode='min', verbose=0, save_best_only=True),\n",
    "#     keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "W0226 16:57:07.720533 13124 deprecation.py:323] From <ipython-input-30-1a3cfc6adddc>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use Model.fit, which supports generators.\nW0226 16:57:07.967872 13124 data_adapter.py:1091] sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nW0226 16:57:08.083563 13124 data_adapter.py:1091] sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 403 steps, validate for 116 steps\nEpoch 1/30\n403/403 [==============================] - 100s 248ms/step - loss: 1.5547 - accuracy: 0.6186 - val_loss: 0.0063 - val_accuracy: 0.9999\nEpoch 2/30\n403/403 [==============================] - 91s 225ms/step - loss: 0.2794 - accuracy: 0.9144 - val_loss: 0.0086 - val_accuracy: 0.9999\nEpoch 3/30\n403/403 [==============================] - 89s 220ms/step - loss: 0.1776 - accuracy: 0.9448 - val_loss: 0.0042 - val_accuracy: 0.9999\nEpoch 4/30\n403/403 [==============================] - 93s 231ms/step - loss: 0.1375 - accuracy: 0.9582 - val_loss: 0.0054 - val_accuracy: 0.9999\nEpoch 5/30\n403/403 [==============================] - 87s 217ms/step - loss: 0.1221 - accuracy: 0.9640 - val_loss: 0.0056 - val_accuracy: 0.9999\nEpoch 6/30\n403/403 [==============================] - 91s 226ms/step - loss: 0.1017 - accuracy: 0.9700 - val_loss: 0.0151 - val_accuracy: 0.9945\nEpoch 7/30\n403/403 [==============================] - 92s 229ms/step - loss: 0.1030 - accuracy: 0.9705 - val_loss: 0.0593 - val_accuracy: 0.9945\nEpoch 8/30\n403/403 [==============================] - 93s 230ms/step - loss: 0.1217 - accuracy: 0.9683 - val_loss: 0.0012 - val_accuracy: 0.9999\nEpoch 9/30\n378/403 [===========================>..] - ETA: 5s - loss: 0.1003 - accuracy: 0.9728"
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=train_num // batch_size,\n",
    "                             epochs=epochs, validation_data=valid_generator,\n",
    "                             validation_steps=valid_num//batch_size,\n",
    "                             callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(output_model_file, monitor='val_loss', mode='min', verbose=0, save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history, label, epochs, min_value, max_value):\n",
    "    data = {}\n",
    "    data[label] = history.history[label]\n",
    "    data['val_'+label] = history.history['val_' + label]\n",
    "    \n",
    "    pd.DataFrame(data).plot(figsize = (8,5))\n",
    "    plt.grid(True)\n",
    "    plt.axis([0, epochs, min_value, max_value])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history, 'accuracy', epochs, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(history, 'loss', epochs, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def load_and_preprocess_single_img(path):\n",
    "    # read the img through file path\n",
    "    image = tf.io.read_file(path)  \n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # 原始图片大小为(128, 128, 3)，重设为(64, 64)\n",
    "    image = tf.image.resize(image, [64, 64])  \n",
    "    image = tf.cast(image, tf.float32) / 255.0  # 归一化到[0,1]范围\n",
    "    image = np.expand_dims(image, axis = 0) # since you have batch_size, so you need to expand your image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_pic(path, show=False):\n",
    "    \n",
    "    if show:\n",
    "        import matplotlib.image as mpimg\n",
    "        plt.imshow(mpimg.imread(path))\n",
    "    image = load_and_preprocess_single_img(path)\n",
    "    predict_result = model.predict(image)\n",
    "    print(\"This is\", label_names[np.argmax(predict_result, axis=1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pic_path = \"./lol_data_2/test2/15.png\"\n",
    "evaluate_single_pic(test_pic_path, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pic_path2 = \"./lol_data_2/test2/21.png\"\n",
    "evaluate_single_pic(test_pic_path2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = model.evaluate(test_generator)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit1184bc59ae474a5b96f7656177dacbec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}